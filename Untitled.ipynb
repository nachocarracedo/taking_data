{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Read App Events\n",
      "# Read Events\n",
      "# Read Phone Brand\n",
      "# Generate Train and Test\n"
     ]
    }
   ],
   "source": [
    "# coding=utf8\n",
    "# Based on yibo's R script\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, scale\n",
    "from sklearn.decomposition import TruncatedSVD, SparsePCA\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Create bag-of-apps in character string format\n",
    "# first by event\n",
    "# then merge to generate larger bags by device\n",
    "\n",
    "##################\n",
    "#   App Events\n",
    "##################\n",
    "print(\"# Read App Events\")\n",
    "app_ev = pd.read_csv(\".\\\\raw_data\\\\app_events.csv\", dtype={'device_id': np.str})\n",
    "# remove duplicates(app_id)\n",
    "app_ev = app_ev.groupby(\"event_id\")[\"app_id\"].apply(lambda x: \" \".join(set(\"app_id:\" + str(s) for s in x)))\n",
    "\n",
    "##################\n",
    "#     Events\n",
    "##################\n",
    "print(\"# Read Events\")\n",
    "events = pd.read_csv(\".\\\\raw_data\\\\events.csv\", dtype={'device_id': np.str})\n",
    "events[\"app_id\"] = events[\"event_id\"].map(app_ev)\n",
    "\n",
    "events = events.dropna()\n",
    "\n",
    "del app_ev\n",
    "\n",
    "events = events[[\"device_id\", \"app_id\"]]\n",
    "\n",
    "# remove duplicates(app_id)\n",
    "events = events.groupby(\"device_id\")[\"app_id\"].apply(lambda x: \" \".join(set(str(\" \".join(str(s) for s in x)).split(\" \"))))\n",
    "events = events.reset_index(name=\"app_id\")\n",
    "\n",
    "# expand to multiple rows\n",
    "events = pd.concat([pd.Series(row['device_id'], row['app_id'].split(' '))for _, row in events.iterrows()]).reset_index()\n",
    "events.columns = ['app_id', 'device_id']\n",
    "\n",
    "##################\n",
    "#   Phone Brand\n",
    "##################\n",
    "print(\"# Read Phone Brand\")\n",
    "pbd = pd.read_csv(\".\\\\raw_data\\\\phone_brand_device_model.csv\", dtype={'device_id': np.str})\n",
    "pbd.drop_duplicates('device_id', keep='first', inplace=True)\n",
    "\n",
    "\n",
    "##################\n",
    "#  Train and Test\n",
    "##################\n",
    "print(\"# Generate Train and Test\")\n",
    "\n",
    "train = pd.read_csv(\".\\\\raw_data\\\\gender_age_train.csv\",dtype={'device_id': np.str})\n",
    "train.drop([\"age\", \"gender\"], axis=1, inplace=True)\n",
    "\n",
    "test = pd.read_csv(\".\\\\raw_data\\\\gender_age_test.csv\",dtype={'device_id': np.str})\n",
    "test[\"group\"] = np.nan\n",
    "\n",
    "\n",
    "split_len = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>device_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_id:-1068679832545653119</td>\n",
       "      <td>-100015673884079572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_id:-506173428906005275</td>\n",
       "      <td>-100015673884079572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_id:-5791102939414640022</td>\n",
       "      <td>-100015673884079572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>app_id:-1633892619084189144</td>\n",
       "      <td>-100015673884079572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>app_id:2812966432357257780</td>\n",
       "      <td>-100015673884079572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        app_id            device_id\n",
       "0  app_id:-1068679832545653119  -100015673884079572\n",
       "1   app_id:-506173428906005275  -100015673884079572\n",
       "2  app_id:-5791102939414640022  -100015673884079572\n",
       "3  app_id:-1633892619084189144  -100015673884079572\n",
       "4   app_id:2812966432357257780  -100015673884079572"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###################\n",
    "#  Concat Feature\n",
    "###################\n",
    "\n",
    "f1 = Df[[\"device_id\", \"phone_brand\"]]   # phone_brand\n",
    "f2 = Df[[\"device_id\", \"device_model\"]]  # device_model\n",
    "f3 = events[[\"device_id\", \"app_id\"]]    # app_id\n",
    "\n",
    "del Df\n",
    "\n",
    "f1.columns.values[1] = \"feature\"\n",
    "f2.columns.values[1] = \"feature\"\n",
    "f3.columns.values[1] = \"feature\"\n",
    "\n",
    "FLS = pd.concat((f1, f2, f3), axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "###################\n",
    "# User-Item Feature\n",
    "###################\n",
    "print(\"# User-Item-Feature\")\n",
    "\n",
    "device_ids = FLS[\"device_id\"].unique()\n",
    "feature_cs = FLS[\"feature\"].unique()\n",
    "\n",
    "data = np.ones(len(FLS))\n",
    "dec = LabelEncoder().fit(FLS[\"device_id\"])\n",
    "row = dec.transform(FLS[\"device_id\"])\n",
    "col = LabelEncoder().fit_transform(FLS[\"feature\"])\n",
    "sparse_matrix = sparse.csr_matrix((data, (row, col)), shape=(len(device_ids), len(feature_cs)))\n",
    "\n",
    "sparse_matrix = sparse_matrix[:, sparse_matrix.getnnz(0) > 0]\n",
    "\n",
    "##################\n",
    "#      Data\n",
    "##################\n",
    "\n",
    "train_row = dec.transform(train[\"device_id\"])\n",
    "train_sp = sparse_matrix[train_row, :]\n",
    "\n",
    "test_row = dec.transform(test[\"device_id\"])\n",
    "test_sp = sparse_matrix[test_row, :]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_sp, Y, train_size=.90, random_state=10)\n",
    "\n",
    "##################\n",
    "#   Feature Sel\n",
    "##################\n",
    "print(\"# Feature Selection\")\n",
    "selector = SelectPercentile(f_classif, percentile=23)\n",
    "\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "X_train = selector.transform(X_train)\n",
    "X_val = selector.transform(X_val)\n",
    "\n",
    "train_sp = selector.transform(train_sp)\n",
    "test_sp = selector.transform(test_sp)\n",
    "\n",
    "print(\"# Num of Features: \", X_train.shape[1])\n",
    "\n",
    "##################\n",
    "#  Build Model\n",
    "##################\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dvalid = xgb.DMatrix(X_val, y_val)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"num_class\": 12,\n",
    "    \"booster\": \"gblinear\",\n",
    "    \"max_depth\": 6,\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"eta\": 0.07,\n",
    "    \"silent\": 1,\n",
    "    \"alpha\": 3,\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "gbm = xgb.train(params, dtrain, 40, evals=watchlist,\n",
    "                early_stopping_rounds=25, verbose_eval=True)\n",
    "\n",
    "print(\"# Train\")\n",
    "dtrain = xgb.DMatrix(train_sp, Y)\n",
    "gbm = xgb.train(params, dtrain, 40, verbose_eval=True)\n",
    "y_pre = gbm.predict(xgb.DMatrix(test_sp))\n",
    "\n",
    "# Write results\n",
    "result = pd.DataFrame(y_pre, columns=lable_group.classes_)\n",
    "result[\"device_id\"] = device_id\n",
    "result = result.set_index(\"device_id\")\n",
    "result.to_csv('fine_tune.gz', index=True,\n",
    "              index_label='device_id', compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
